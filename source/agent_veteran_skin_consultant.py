import os
import sys
import pandas as pd
from dotenv import load_dotenv
from typing import Dict, List, Any

# LangChain ë° Pydantic ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

# google.genai í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì„í¬íŠ¸
from google import genai
from google.genai import types
from google.genai.types import File, ContentDict

# --- 1. ì‚¬ì „ ì„¤ì • ---
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise ValueError("'.env' íŒŒì¼ì— GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# í”„ë¡œì íŠ¸ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# ì´ íŒŒì¼(agent_veteran_skin_consultant.py)ì´ 'source' í´ë” ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PROMPT_FILE_PATH = os.path.join(BASE_DIR, "source", "prompt", "veteran_skin_consultant.txt")
HOSPITAL_CSV_PATH = os.path.join(BASE_DIR, "data", "hospital_list", "gangnam_unni_final_aggressive.csv")
TEXTBOOK_DIR_PATH = os.path.join(BASE_DIR, "data", "textbook")

PROCEDURE_CATEGORIES = ["í•„ëŸ¬", "ë³´í†¡ìŠ¤", "ëª¨ë°œì´ì‹", "ì œëª¨", 'í”¼ë¶€', 'ë¦¬í”„íŒ…']

# --- 2. Pydantic ëª¨ë¸ ì •ì˜ ---
class ProcedureCategory(BaseModel):
    is_detected: bool = Field(description="ì£¼ì–´ì§„ ì„ íƒì§€ ì¤‘ì—ì„œ ê´€ë ¨ ì‹œìˆ  ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì•˜ëŠ”ì§€ ì—¬ë¶€")
    category: str = Field(description=f"ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì‹œìˆ  ì¹´í…Œê³ ë¦¬. ë°˜ë“œì‹œ ë‹¤ìŒ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•¨: {', '.join(PROCEDURE_CATEGORIES)}")

class PdfSelection(BaseModel):
    selected_filename: str = Field(description="ì œê³µëœ PDF ìš”ì•½ ëª©ë¡ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ê°€ì¥ ë„ì›€ì´ ë  PDF íŒŒì¼ì˜ ì´ë¦„ì„ ì„ íƒí•©ë‹ˆë‹¤.")

# --- 3. ë°ì´í„° ë¡œë”© ë° ì²´ì¸ ìƒì„± í•¨ìˆ˜ ---

def upload_all_pdfs_once(directory_path: str, api_client: genai.Client) -> Dict[str, File]:
    """[ìµœì´ˆ 1íšŒ ì‹¤í–‰] ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  PDFë¥¼ ì—…ë¡œë“œí•˜ê³ , íŒŒì¼ëª…ì„ í‚¤ë¡œ í•˜ëŠ” í•¸ë“¤ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    uploaded_file_handles = {}
    print(f"'{directory_path}'ì˜ ëª¨ë“  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤ (ìµœì´ˆ 1íšŒ ì‹¤í–‰)...")
    for root, _, files in os.walk(directory_path):
        for file in files:
            if file.lower().endswith(".pdf"):
                filepath = os.path.join(root, file)
                try:
                    print(f"-> Uploading: {file}")
                    # âœ… ìˆ˜ì •: 'create' -> 'upload_file'ë¡œ ë³€ê²½í•˜ê³ , íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ì‚¬ìš©
                    uploaded_file = api_client.files.upload(
                        file=filepath
                    )
                    uploaded_file_handles[file] = uploaded_file
                except Exception as e:
                    print(f"ğŸš¨ ê²½ê³ : '{file}' íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ì´ íŒŒì¼ì€ ê±´ë„ˆëœë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
    print(f"âœ… ì´ {len(uploaded_file_handles)}ê°œì˜ PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return uploaded_file_handles

def get_pdf_summaries() -> Dict[str, str]:
    return {
        "Cosmetic Dermatology- Products And Procedures Cosmetic -- Draelos, Zoe Kececioglu -- ( WeLib.org ).pdf": "ìµœì‹  ì‹œìˆ  í˜ì‹  ì •ë³´...",
        "Injectable Fillers in Aesthetic Medicine -- Mauricio de Maio, Berthold Rzany (auth.) -- ( WeLib.org ).pdf": "ë¯¸ìš© í•„ëŸ¬ì˜ ì„ìƒ ì‚¬ìš© ê°œìš”. ...", # <-- ì´ ë¶€ë¶„ ìˆ˜ì •
        "Skills for Communicating with Patients, 3rd Edition -- Juliet Draper, Suzanne M. Kurtz, Jonathan Silverman -- ( WeLib.org ).pdf": "í™˜ìì™€ì˜ íš¨ê³¼ì ì¸ ì†Œí†µ ê¸°ìˆ  íƒêµ¬. ...",
        "Textbook of Cosmetic Dermatology (Series in Cosmetic and -- Robert L Baran; Howard Ira Maibach -- ( WeLib.org ).pdf": "ë¯¸ìš© í”¼ë¶€ê³¼í•™ì˜ ê³¼í•™ì  ê·¼ê±°ë¥¼ ë¬¸ì„œí™”. ..."
    }

def create_pdf_selection_chain(llm: ChatGoogleGenerativeAI, pdf_summaries: Dict[str, str]):
    """PDF ìš”ì•½ë³¸ì„ ë³´ê³  ê°€ì¥ ì ì ˆí•œ íŒŒì¼ì„ ì„ íƒí•˜ëŠ” LangChain ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    summaries_text = "\n".join([f"- íŒŒì¼ëª…: {fname}\n  ìš”ì•½: {summary}" for fname, summary in pdf_summaries.items()])
    system_prompt = f"ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ê°€ì¥ ë„ì›€ì´ ë  ì°¸ê³  ìë£Œ(PDF)ë¥¼ ë‹¨ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ PDF íŒŒì¼ë“¤ì˜ ìš”ì•½ ëª©ë¡ì„ ë³´ê³ , ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ íŒŒì¼ì˜ ì´ë¦„ì„ ì •í™•íˆ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. << PDF ìš”ì•½ ëª©ë¡ >>\n{summaries_text}"

    # âœ… ìˆ˜ì •: listë¥¼ ChatPromptTemplate.from_messagesë¡œ ê°ì‹¸ì¤ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {query}")
    ])

    structured_llm = llm.with_structured_output(PdfSelection)
    return prompt | structured_llm

def create_category_extraction_chain(llm: ChatGoogleGenerativeAI, categories_list: List[str]):
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì‹œìˆ  ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•˜ëŠ” LangChain ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    system_prompt = f"ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²ƒì„ í•˜ë‚˜ë§Œ ë¶„ë¥˜í•˜ì„¸ìš”: {', '.join(categories_list)}. ê´€ë ¨ ì—†ìœ¼ë©´ is_detectedë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”."

    # âœ… ìˆ˜ì •: listë¥¼ ChatPromptTemplate.from_messagesë¡œ ê°ì‹¸ì¤ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {query}")
    ])

    structured_llm = llm.with_structured_output(ProcedureCategory)
    return prompt | structured_llm

def load_prompt_from_file(filepath: str) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f: return f.read()
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : í”„ë¡¬í”„íŠ¸ íŒŒì¼ '{filepath}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        return "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í”¼ë¶€ê³¼ ìƒë‹´ ì‹¤ì¥ì…ë‹ˆë‹¤."

def load_and_filter_hospitals(csv_path: str, category: str | None) -> str:
    """CSV íŒŒì¼ì—ì„œ ë³‘ì› ëª©ë¡ì„ ë¡œë“œí•˜ê³  íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤."""
    if not category: return "ê´€ë ¨ ì‹œìˆ  ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì§€ ëª»í•´ ë³‘ì› ì •ë³´ë¥¼ í•„í„°ë§í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    try:
        df = pd.read_csv(csv_path)
        filtered_df = df[df['ì¹´í…Œê³ ë¦¬'].str.contains(category, na=False)]
        if filtered_df.empty: return f"'{category}' ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë³‘ì› ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        # ìƒìœ„ 5ê°œ ë³‘ì› ì •ë³´ë§Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return filtered_df.head(5).to_string(index=False)
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : ë³‘ì› ëª©ë¡ íŒŒì¼ '{csv_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return "ë³‘ì› ëª©ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë³‘ì› ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# --- 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    # í‘œì¤€ ì…ì¶œë ¥(stdin, stdout)ì˜ ì¸ì½”ë”©ì„ UTF-8ë¡œ ê°•ì œ ì„¤ì •
    # í„°ë¯¸ë„ í™˜ê²½ì— ë”°ë¼ export ì„¤ì •ì´ ì ìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì œë¥¼ ì½”ë“œ ë ˆë²¨ì—ì„œ í•´ê²°
    try:
        sys.stdin.reconfigure(encoding='utf-8')
        sys.stdout.reconfigure(encoding='utf-8')
        print("âœ… ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì—ì„œ í‘œì¤€ ì…ì¶œë ¥ ì¸ì½”ë”©ì„ UTF-8ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ ê²½ê³ : ì¸ì½”ë”© ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")

    print("ğŸ§  ì§€ëŠ¥í˜• PDF ì„ íƒ ê¸°ëŠ¥ì´ í¬í•¨ëœ í”¼ë¶€ê³¼ ìƒë‹´ ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # âœ… 1. genai.Clientë¥¼ ì²˜ìŒì— í•œ ë²ˆë§Œ ìƒì„±í•˜ì—¬ ê³µìœ 
    client = genai.Client(api_key=GOOGLE_API_KEY)

    # 2. PDF ì—…ë¡œë“œ ë° ìš”ì•½ë³¸ ë¡œë“œ
    pdf_handles_dict = upload_all_pdfs_once(TEXTBOOK_DIR_PATH, client)
    pdf_summaries_dict = get_pdf_summaries()

    if not pdf_handles_dict:
        print("ì—…ë¡œë“œëœ PDFê°€ ì—†ì–´ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    # âœ… 3. ê³µìœ ëœ clientë¥¼ ì‚¬ìš©í•˜ì—¬ LangChain LLM ì´ˆê¸°í™”
    llm_for_chains = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro-latest",
        temperature=0,
        client=client
    )

    # 4. êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ ì²´ì¸ë“¤ ìƒì„±
    pdf_selector_chain = create_pdf_selection_chain(llm_for_chains, pdf_summaries_dict)
    category_extraction_chain = create_category_extraction_chain(llm_for_chains, PROCEDURE_CATEGORIES)

    # 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    system_prompt_template = load_prompt_from_file(PROMPT_FILE_PATH)
    conversation_history: List[ContentDict] = []

    while True:
        # --- [ìˆ˜ì •ëœ ì…ë ¥ ì²˜ë¦¬ ë¶€ë¶„ ì‹œì‘] ---
        # 1. í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ì¦‰ì‹œ í‘œì‹œë˜ë„ë¡ í•©ë‹ˆë‹¤.
        print("\nAsk Me Anything! : ", end="", flush=True)

        # 2. í‘œì¤€ ì…ë ¥ ë²„í¼ì—ì„œ ì¸ì½”ë”©ë˜ì§€ ì•Šì€ ì›ì‹œ(raw) ë°”ì´íŠ¸ë¥¼ ì§ì ‘ ì½ìŠµë‹ˆë‹¤.
        user_input_bytes = sys.stdin.buffer.readline()

        # 3. ë°”ì´íŠ¸ë¥¼ 'euc-kr'ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ 'utf-8'ë¡œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.
        try:
            user_input = user_input_bytes.decode('euc-kr').strip()
        except UnicodeDecodeError:
            user_input = user_input_bytes.decode('utf-8').strip()

        # ì‚¬ìš©ìê°€ ì•„ë¬´ê²ƒë„ ì…ë ¥í•˜ì§€ ì•Šê³  ì—”í„°ë§Œ ì³¤ì„ ê²½ìš°, ë£¨í”„ì˜ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
        if not user_input:
            continue
        # --- [ìˆ˜ì •ëœ ì…ë ¥ ì²˜ë¦¬ ë¶€ë¶„ ë] ---

        if user_input.lower() in ['exit', 'ì¢…ë£Œ']:
            print("ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ë‹¨ê³„ 1: ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ PDF ì„ íƒ
        print("ğŸ“š ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì°¸ê³ ìë£Œ(PDF)ë¥¼ ì„ íƒ ì¤‘ì…ë‹ˆë‹¤...")
        selection_result = pdf_selector_chain.invoke({"query": user_input})
        selected_filename = selection_result.selected_filename
        selected_pdf_handle = pdf_handles_dict.get(selected_filename)
        if selected_pdf_handle:
            print(f"âœ… ì„ íƒëœ íŒŒì¼: {selected_filename}")
        else:
            print(f"ğŸš¨ ê²½ê³ : ì„ íƒëœ íŒŒì¼ '{selected_filename}'ì˜ í•¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²¨ë¶€ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")

        # ë‹¨ê³„ 2: ì‹œìˆ  ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
        print("ğŸ’¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œìˆ  ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡  ì¤‘ì…ë‹ˆë‹¤...")
        category_info = category_extraction_chain.invoke({"query": user_input})
        category = category_info.category if category_info.is_detected else None
        print(f"âœ… ì¶”ë¡ ëœ ì¹´í…Œê³ ë¦¬: {category or 'ì—†ìŒ'}")

        # ë‹¨ê³„ 3: ë³‘ì› ì •ë³´ í•„í„°ë§
        hospital_info_str = load_and_filter_hospitals(HOSPITAL_CSV_PATH, category)

        # âœ… [ìˆ˜ì •] ë‹¨ê³„ 4: API í˜¸ì¶œ ì „, í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” ê¸°ë¡ì— ë¯¸ë¦¬ ì¶”ê°€
        current_user_parts = [user_input]
        if selected_pdf_handle:
            current_user_parts.append(selected_pdf_handle)
        conversation_history.append({'role': 'user', 'parts': current_user_parts})

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ì—ì„œ ì‹œìŠ¤í…œ ë¶€ë¶„ë§Œ ë¶„ë¦¬
        final_system_prompt = system_prompt_template.replace("((HOSPITAL_LIST))", hospital_info_str) \
                                                    .replace("((SUBMITTED_PHOTOS))", "ì‚¬ìš©ìê°€ ì œì¶œí•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.") \
                                                    .replace("((CONVERSATION_HISTORY))", str(conversation_history))

        print("\nğŸ¤– ìƒë‹´ ì‹¤ì¥ì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” ì¤‘...")
        response = client.models.generate_content(
            model="gemini-1.5-flash-latest",
            contents=final_system_prompt,
            config=types.GenerateContentConfig(
                temperature=0.3
            )
        )
        response_text = response.text
        print(f"\nìƒë‹´ ì‹¤ì¥: {response_text}")

        # âœ… [ìˆ˜ì •] ë‹¨ê³„ 5: ëª¨ë¸ì˜ ë‹µë³€ë§Œ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ì‚¬ìš©ì ì…ë ¥ì€ ì´ë¯¸ ì¶”ê°€ë¨)
        conversation_history.append({'role': 'model', 'parts': response_text})